{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d68afb-1223-41b3-af1c-5f1e3601d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2000 rows of synthetic data...\n",
      "Data generation complete.\n",
      "\n",
      "Dataset saved to 'procrastination_big_data.csv'\n",
      "Here's a sample of your new 'big data':\n",
      "           Actual_Start_Time          Task_Name   Task_Category  \\\n",
      "0 2024-09-19 11:51:56.039245        Cook dinner           Chore   \n",
      "1 2024-09-19 14:02:49.444877    Reply to emails    Admin/Emails   \n",
      "2 2024-09-19 16:22:31.297570  Revise DBMS notes  Study/Research   \n",
      "3 2024-09-19 22:01:12.119359   Prepare for quiz  Study/Research   \n",
      "4 2024-09-20 01:01:13.292040          Pay bills           Chore   \n",
      "\n",
      "   Estimated_Duration_Mins Deadline_Date         Planned_Start_Time  \\\n",
      "0                       10    2024-10-07 2024-09-19 10:01:49.541071   \n",
      "1                       10    2024-10-19 2024-09-19 12:15:15.985310   \n",
      "2                      103    2024-09-30 2024-09-19 14:55:28.019911   \n",
      "3                      103    2024-10-02 2024-09-19 20:35:08.641878   \n",
      "4                       44    2024-10-09 2024-09-19 23:12:07.358020   \n",
      "\n",
      "   Mood_Level_1_5  Energy_Level_1_5  Hours_of_Sleep  Perceived_Enjoyment_1_5  \n",
      "0               1                 3             7.6                        1  \n",
      "1               3                 3             7.0                        1  \n",
      "2               2                 2             3.8                        3  \n",
      "3               1                 2             8.8                        3  \n",
      "4               3                 4             7.6                        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_procrastination_data(num_rows=2000):\n",
    "    \"\"\"\n",
    "    Generates a large, realistic synthetic dataset for the procrastination project.\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_rows} rows of synthetic data...\")\n",
    "\n",
    "    # --- 1. Define the Persona & Task Probabilities ---\n",
    "    task_templates = {\n",
    "        'Code': ['Work on FYP module', 'Debug API endpoint', 'Solve LeetCode problem', 'Refactor legacy code', 'Update project dependencies'],\n",
    "        'Study/Research': ['Read research paper', 'Revise DBMS notes', 'Work on lab assignment', 'Prepare for quiz', 'Write documentation'],\n",
    "        'Chore': ['Do laundry', 'Clean room', 'Grocery shopping', 'Cook dinner', 'Pay bills'],\n",
    "        'Admin/Emails': ['Reply to emails', 'Plan the week', 'Update resume', 'Submit assignment online'],\n",
    "        'Health/Fitness': ['Go for a run', 'Workout at the gym', 'Go for a walk', 'Meditate'],\n",
    "        'Social': ['Call parents', 'Meet friends for dinner', 'Attend team meeting', 'Go to a movie']\n",
    "    }\n",
    "    \n",
    "    # Define probabilities and characteristics for each category\n",
    "    task_info = {\n",
    "        'Code': {'prob': 0.30, 'avg_enjoyment': 3.5, 'avg_duration': 120},\n",
    "        'Study/Research': {'prob': 0.30, 'avg_enjoyment': 2.0, 'avg_duration': 90},\n",
    "        'Chore': {'prob': 0.15, 'avg_enjoyment': 1.5, 'avg_duration': 45},\n",
    "        'Admin/Emails': {'prob': 0.10, 'avg_enjoyment': 2.0, 'avg_duration': 20},\n",
    "        'Health/Fitness': {'prob': 0.08, 'avg_enjoyment': 4.0, 'avg_duration': 60},\n",
    "        'Social': {'prob': 0.07, 'avg_enjoyment': 4.5, 'avg_duration': 75}\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    # Start generating data from one year ago\n",
    "    current_time = datetime.now() - timedelta(days=365)\n",
    "\n",
    "    # --- 2. Main Generation Loop ---\n",
    "    for i in range(num_rows):\n",
    "        # Choose a task category based on probabilities\n",
    "        category = random.choices(list(task_info.keys()), weights=[v['prob'] for v in task_info.values()])[0]\n",
    "        \n",
    "        # --- 3. Simulate Personal State ---\n",
    "        hours_of_sleep = np.random.normal(7.0, 1.5) # Normally distributed around 7 hours\n",
    "        \n",
    "        # Energy is correlated with sleep\n",
    "        energy_level = max(1, min(5, int(np.random.normal(2 + (hours_of_sleep / 4), 1))))\n",
    "        \n",
    "        # Mood is correlated with energy but has more randomness\n",
    "        mood_level = max(1, min(5, int(np.random.normal(energy_level, 1.5))))\n",
    "        \n",
    "        # --- 4. Simulate Task Characteristics ---\n",
    "        task_name = random.choice(task_templates[category])\n",
    "        est_duration = max(10, int(np.random.normal(task_info[category]['avg_duration'], 20)))\n",
    "        perceived_enjoyment = max(1, min(5, int(np.random.normal(task_info[category]['avg_enjoyment'], 1))))\n",
    "        \n",
    "        deadline_date = (current_time + timedelta(days=random.randint(1, 30))).date()\n",
    "        deadline_proximity = (deadline_date - current_time.date()).days\n",
    "\n",
    "        # --- 5. The Procrastination Logic ---\n",
    "        # Start with a base delay, add penalties based on context\n",
    "        delay_minutes = random.uniform(0, 20) # Base random delay\n",
    "        \n",
    "        # Penalty for low enjoyment & energy\n",
    "        delay_minutes += (5 - perceived_enjoyment) * random.uniform(10, 20)\n",
    "        delay_minutes += (5 - energy_level) * random.uniform(5, 15)\n",
    "        \n",
    "        # Penalty for certain task types\n",
    "        if category in ['Study/Research', 'Chore']:\n",
    "            delay_minutes += random.uniform(0, 30)\n",
    "            \n",
    "        # \"Panic Monster\": reduce delay if deadline is very close\n",
    "        if deadline_proximity <= 2:\n",
    "            delay_minutes *= 0.25 # Drastically reduce delay\n",
    "        \n",
    "        # --- 6. Finalize Timestamps ---\n",
    "        actual_start_time = current_time\n",
    "        planned_start_time = actual_start_time - timedelta(minutes=delay_minutes)\n",
    "        \n",
    "        # Append the generated row\n",
    "        data.append({\n",
    "            'Actual_Start_Time': actual_start_time,\n",
    "            'Task_Name': task_name,\n",
    "            'Task_Category': category,\n",
    "            'Estimated_Duration_Mins': est_duration,\n",
    "            'Deadline_Date': deadline_date,\n",
    "            'Planned_Start_Time': planned_start_time,\n",
    "            'Mood_Level_1_5': mood_level,\n",
    "            'Energy_Level_1_5': energy_level,\n",
    "            'Hours_of_Sleep': round(max(3, hours_of_sleep), 1),\n",
    "            'Perceived_Enjoyment_1_5': perceived_enjoyment\n",
    "        })\n",
    "        \n",
    "        # Increment time for the next task (simulates passage of time)\n",
    "        current_time += timedelta(hours=random.uniform(2, 6))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Data generation complete.\")\n",
    "    return df\n",
    "\n",
    "# --- Generate the data and save it to a CSV file ---\n",
    "big_df = generate_procrastination_data(num_rows=2000)\n",
    "big_df.to_csv('procrastination_big_data.csv', index=False)\n",
    "\n",
    "print(\"\\nDataset saved to 'procrastination_big_data.csv'\")\n",
    "print(\"Here's a sample of your new 'big data':\")\n",
    "print(big_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f9cc51-9e02-490c-b65e-ec54677f2955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2000 rows with V2 logic...\n",
      "Data generation complete.\n",
      "\n",
      "Dataset saved to 'procrastination_big_data_v2.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_procrastination_data_v2(num_rows=2000):\n",
    "    \"\"\"\n",
    "    Generates a large synthetic dataset with more pronounced procrastination habits.\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_rows} rows with V2 logic...\")\n",
    "\n",
    "    # --- TUNING PARAMETER ---\n",
    "    # Increase this value to make the persona more likely to procrastinate\n",
    "    PROCRASTINATION_TENDENCY = 1.5 \n",
    "\n",
    "    task_templates = {\n",
    "        'Code': ['Work on FYP module', 'Debug API endpoint', 'Solve LeetCode problem', 'Refactor legacy code', 'Update project dependencies'],\n",
    "        'Study/Research': ['Read research paper', 'Revise DBMS notes', 'Work on lab assignment', 'Prepare for quiz', 'Write documentation'],\n",
    "        'Chore': ['Do laundry', 'Clean room', 'Grocery shopping', 'Cook dinner', 'Pay bills'],\n",
    "        'Admin/Emails': ['Reply to emails', 'Plan the week', 'Update resume', 'Submit assignment online'],\n",
    "        'Health/Fitness': ['Go for a run', 'Workout at the gym', 'Go for a walk', 'Meditate'],\n",
    "        'Social': ['Call parents', 'Meet friends for dinner', 'Attend team meeting', 'Go to a movie']\n",
    "    }\n",
    "    \n",
    "    task_info = {\n",
    "        'Code': {'prob': 0.30, 'avg_enjoyment': 3.5, 'avg_duration': 120},\n",
    "        'Study/Research': {'prob': 0.30, 'avg_enjoyment': 2.0, 'avg_duration': 90},\n",
    "        'Chore': {'prob': 0.15, 'avg_enjoyment': 1.5, 'avg_duration': 45},\n",
    "        'Admin/Emails': {'prob': 0.10, 'avg_enjoyment': 2.0, 'avg_duration': 20},\n",
    "        'Health/Fitness': {'prob': 0.08, 'avg_enjoyment': 4.0, 'avg_duration': 60},\n",
    "        'Social': {'prob': 0.07, 'avg_enjoyment': 4.5, 'avg_duration': 75}\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "    current_time = datetime.now() - timedelta(days=365)\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        category = random.choices(list(task_info.keys()), weights=[v['prob'] for v in task_info.values()])[0]\n",
    "        \n",
    "        hours_of_sleep = np.random.normal(7.0, 1.5)\n",
    "        energy_level = max(1, min(5, int(np.random.normal(2 + (hours_of_sleep / 4), 1))))\n",
    "        mood_level = max(1, min(5, int(np.random.normal(energy_level, 1.5))))\n",
    "        \n",
    "        task_name = random.choice(task_templates[category])\n",
    "        est_duration = max(10, int(np.random.normal(task_info[category]['avg_duration'], 20)))\n",
    "        perceived_enjoyment = max(1, min(5, int(np.random.normal(task_info[category]['avg_enjoyment'], 1))))\n",
    "        \n",
    "        deadline_date = (current_time + timedelta(days=random.randint(1, 30))).date()\n",
    "        deadline_proximity = (deadline_date - current_time.date()).days\n",
    "\n",
    "        # --- ADJUSTED PROCRASTINATION LOGIC ---\n",
    "        delay_minutes = random.uniform(0, 15)\n",
    "        \n",
    "        # INCREASED PENALTIES: Penalties are now higher and multiplied by our tendency factor\n",
    "        delay_minutes += (5 - perceived_enjoyment) * random.uniform(15, 30) * PROCRASTINATION_TENDENCY\n",
    "        delay_minutes += (5 - energy_level) * random.uniform(10, 20) * PROCRASTINATION_TENDENCY\n",
    "        \n",
    "        if category in ['Study/Research', 'Chore', 'Admin/Emails']:\n",
    "            delay_minutes += random.uniform(10, 40)\n",
    "            \n",
    "        # SOFTENED PANIC MONSTER: Effect is less drastic and only applies when deadline is 1 day away\n",
    "        if deadline_proximity <= 1:\n",
    "            delay_minutes *= 0.5 \n",
    "        \n",
    "        actual_start_time = current_time\n",
    "        planned_start_time = actual_start_time - timedelta(minutes=delay_minutes)\n",
    "        \n",
    "        data.append({\n",
    "            'Actual_Start_Time': actual_start_time,\n",
    "            'Task_Name': task_name,\n",
    "            'Task_Category': category,\n",
    "            'Estimated_Duration_Mins': est_duration,\n",
    "            'Deadline_Date': deadline_date,\n",
    "            'Planned_Start_Time': planned_start_time,\n",
    "            'Mood_Level_1_5': mood_level,\n",
    "            'Energy_Level_1_5': energy_level,\n",
    "            'Hours_of_Sleep': round(max(3, hours_of_sleep), 1),\n",
    "            'Perceived_Enjoyment_1_5': perceived_enjoyment\n",
    "        })\n",
    "        \n",
    "        current_time += timedelta(hours=random.uniform(2, 6))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Data generation complete.\")\n",
    "    return df\n",
    "\n",
    "# --- Generate the new data and save it ---\n",
    "big_df_v2 = generate_procrastination_data_v2(num_rows=2000)\n",
    "big_df_v2.to_csv('procrastination_big_data_v2.csv', index=False)\n",
    "\n",
    "print(\"\\nDataset saved to 'procrastination_big_data_v2.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df582c6-bc6a-43f6-b604-69f6e9c2708f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Meme Analysis)",
   "language": "python",
   "name": "meme_analysis_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
